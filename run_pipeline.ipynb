{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b368e74",
   "metadata": {},
   "source": [
    "## CREATE MODEL CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e05c0",
   "metadata": {},
   "source": [
    "### Define project name, username"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa0690c",
   "metadata": {},
   "source": [
    "![workflowimage](Images/pic2.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8352940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProjectName = 'sampleproject-testing' # ex: 'cicd-hbbchurn'\n",
    "DepartmentName = 'sample-department-name' \n",
    "UsecaseName = 'sample-usecase' # ex: 'mlops-cicd'\n",
    "UserName = 'mlops-lakshani'\n",
    "BUName = 'mlops' # ex: 'mlops'\n",
    "AD = 'sample-ad-name' \n",
    "ResourceName = 'sample-resource-name'\n",
    "OwnerName = 'saranga_gunasekara'\n",
    "env = 'dev'\n",
    "job_name = ''\n",
    "\n",
    "project_prefix = f'{ProjectName}/{BUName}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2b686",
   "metadata": {},
   "source": [
    "# RUN PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08738c",
   "metadata": {},
   "source": [
    "![workflowimage](Images/pic3.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a747a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "#from model from mlops_experiment_and_trial_training import mlops_model_experiments\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "from sagemaker.workflow.steps import CacheConfig\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput,TransformInput,CreateModelInput\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor,\n",
    ")\n",
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.conditions import (\n",
    "    ConditionGreaterThanOrEqualTo,\n",
    ")\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    ")\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    "    TransformStep,\n",
    "    CreateModelStep\n",
    ")\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.model import Model\n",
    "\n",
    "from sagemaker.workflow.pipeline_context import LocalPipelineSession\n",
    "local_pipeline_session = LocalPipelineSession()\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1322ac64",
   "metadata": {},
   "source": [
    "![workflowimage](Images/pic4.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b58b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'sm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c8ce725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session(region, default_bucket):\n",
    "    \"\"\"Gets the sagemaker session based on the region.\n",
    "    Args:\n",
    "        region: the aws region to start the session\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "    Returns:\n",
    "        `sagemaker.session.Session instance\n",
    "    \"\"\"\n",
    "\n",
    "    boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "    sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "    #cloudwatch_client = boto_session.client(\"cloudwatch\")\n",
    "    runtime_client = boto_session.client(\"sagemaker-runtime\")\n",
    "    return sagemaker.session.Session(\n",
    "        boto_session=boto_session,\n",
    "        sagemaker_client=sagemaker_client,\n",
    "        sagemaker_runtime_client=runtime_client,\n",
    "        default_bucket=default_bucket,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4723c475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "srilanka_tz = pytz.timezone('Asia/Colombo')\n",
    "date_folder = datetime.now(srilanka_tz).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c9019a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling the config file\n",
      "[LOG] dlk-cloud-tier-8-code-ml-dev ---------\n",
      "[LOG] config_files/aif_config/sampleproject-testing/mlops/config.json --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def getJsonData(bucket_name,key_name):\n",
    "    '''\n",
    "    this will pick the json config file from s3 bucket\n",
    "    '''\n",
    "    \n",
    "    print(\"[LOG]\", bucket_name,'---------')\n",
    "    print(\"[LOG]\", key_name,'--------------')\n",
    "      \n",
    "    s3_client = boto3.client('s3')\n",
    "    csv_obj = s3_client.get_object(Bucket=bucket_name, Key=key_name)\n",
    "    \n",
    "    body = csv_obj['Body']\n",
    "    \n",
    "    json_string = body.read().decode('utf-8')\n",
    "    json_content = json.loads(json_string)\n",
    "    \n",
    "    return json_content\n",
    "\n",
    "print(\"calling the config file\")\n",
    "config_bucket_name = f'dlk-cloud-tier-8-code-ml-{env}'\n",
    "config_key_name = f'config_files/aif_config/{project_prefix}/config.json' \n",
    "config = getJsonData(config_bucket_name,config_key_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bcbb5d",
   "metadata": {},
   "source": [
    "![workflowimage](Images/pic7.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f15d9e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline(\n",
    "    region,\n",
    "    subnets,\n",
    "    security_group_ids,\n",
    "    role=None,\n",
    "    default_bucket=None,\n",
    "    model_package_group_name=config['ModelSpecific']['ModelPackageGroupName'],  # Choose any name\n",
    "    pipeline_name=config['PipelineSpecific']['PipelineNamePrefix'],  # You can find your pipeline name in the Studio UI (project -> Pipelines -> name)\n",
    "    base_job_prefix=config['UserDetails']['BUName'],  # Choose any name\n",
    "    env=config['UserDetails']['EnvironmentName'],\n",
    "    project_name = config['UserDetails']['ProjectName']\n",
    "):\n",
    "    \n",
    "    project_name = config[\"UserDetails\"][\"ProjectName\"]\n",
    "    user_name=config[\"UserDetails\"][\"UserName\"]\n",
    "    BU_name = config[\"UserDetails\"][\"BUName\"]\n",
    "    \n",
    "    \"\"\"Gets a SageMaker ML Pipeline instance working with on CustomerChurn data.\n",
    "    Args:\n",
    "        region: AWS region to create and run the pipeline.\n",
    "        role: IAM role to create and run steps and pipeline.\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "    Returns:\n",
    "        an instance of a pipeline\n",
    "    \"\"\"\n",
    "    #data versioning control using date\n",
    "    srilanka_tz = pytz.timezone('Asia/Colombo')\n",
    "    s3 = boto3.client('s3')\n",
    "    cw = boto3.client('cloudwatch')\n",
    "    date_folder = datetime.now(srilanka_tz).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    #working with input data path\n",
    "    input_data = config['S3LocationPaths']['PreprocessPath']\n",
    "    \n",
    "    #working with output data path   \n",
    "    preprocessed_output1 = f\"s3://dlk-cloud-tier-10-preprocessed-ml-{env}/{project_name}/train/output1/\"\n",
    "    preprocessed_output2 = f\"s3://dlk-cloud-tier-10-preprocessed-ml-{env}/{project_name}/train/output2/\"\n",
    "    #preprocessed_output3 = f\"s3://dlk-cloud-tier-10-preprocessed-ml-{env}/{project_name}/train/{date_folder}/output3/\"\n",
    "    #preprocessed_output4 = f\"s3://dlk-cloud-tier-10-preprocessed-ml-{env}/{project_name}/train/{date_folder}/output4/\"\n",
    "\n",
    "    \n",
    "    generic_tags=[{'Key': 'dialog:mlops:environmentname', 'Value': config['TagSpecific']['dialog:mlops:environmentname']}, \n",
    "                  {'Key': 'dialog:mlops:projectname', 'Value': config['TagSpecific']['dialog:mlops:projectname']},\n",
    "                  {'Key': 'dialog:mlops:departmentname', 'Value': config['TagSpecific']['dialog:mlops:departmentname']},\n",
    "                  {'Key': 'dialog:mlops:resourcename', 'Value': config['TagSpecific']['dialog:mlops:resourcename']}, \n",
    "                  {'Key': 'dialog:mlops:ownername', 'Value': config['TagSpecific']['dialog:mlops:ownername']},\n",
    "                  {'Key': 'dialog:mlops:buname', 'Value': config['TagSpecific']['dialog:mlops:buname']} ]\n",
    "    \n",
    "    \n",
    "    sagemaker_session = get_session(region, default_bucket)\n",
    "    if role is None:\n",
    "        role = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "    account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "    region = boto3.session.Session().region_name\n",
    "\n",
    "    # Parameters for pipeline execution\n",
    "    model_path = ParameterString(\n",
    "        name=\"ModelPath\",\n",
    "        default_value=f\"s3://dlk-cloud-tier-9-training-ml-{env}/{project_name}/{date_folder}\", \n",
    "    )\n",
    "    \n",
    "    model_approval_status = ParameterString(\n",
    "        name=\"ModelApprovalStatus\",\n",
    "        default_value=\"Approved\",  # ModelApprovalStatus can be set to a default of \"Approved\" if you don't want manual approval.\n",
    "    )\n",
    "\n",
    "    # -------------------------- PREPROCESSING --------------------------------------------------------------------\n",
    "\n",
    "        \n",
    "    script_processor = ScriptProcessor(\n",
    "         command = [\"python3\"],\n",
    "         image_uri = config['DockerSpecific']['PreprocessURI'],\n",
    "         role = role,\n",
    "         instance_count = 1, #config['PipelineSpecific']['Preprocessing']['InstanceCount'],\n",
    "         instance_type = config['PipelineSpecific']['Preprocessing']['InstanceType'],\n",
    "         tags = generic_tags + [{'Key': 'JobType', 'Value': 'Preprocessing'}],\n",
    "         network_config = NetworkConfig(subnets=subnets.split(':'), security_group_ids=security_group_ids.split(':'))\n",
    "    )\n",
    "    \n",
    "    step_preprocess = ProcessingStep(\n",
    "        name= f'{BUName}-{UsecaseName}-preprocessing',\n",
    "        processor= script_processor, \n",
    "        code= 'mlops_sampleusecase_preprocessing/preprocessing.py',\n",
    "        inputs= [ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "                ProcessingInput(source='mlops_sampleusecase_preprocessing/my_package/', destination=\"/opt/ml/processing/input/code/my_package/\"),\n",
    "                #ProcessingInput(source=input_data3, destination=\"/opt/ml/processing/input3\"),\n",
    "                #ProcessingInput(source=input_data4, destination=\"/opt/ml/processing/input4\"),\n",
    "\n",
    "               ],\n",
    "        outputs= [\n",
    "            ProcessingOutput(output_name=\"output1\", destination=preprocessed_output1, source=\"/opt/ml/processing/output1\"),\n",
    "            ProcessingOutput(output_name=\"output2\", destination=preprocessed_output2,  source=\"/opt/ml/processing/output2\"),\n",
    "            #ProcessingOutput(output_name=\"output3\", destination=preprocessed_output3,  source=\"/opt/ml/processing/output3\"),\n",
    "            #ProcessingOutput(output_name=\"output4\", destination=preprocessed_output2,  source=\"/opt/ml/processing/output4\"),\n",
    "           \n",
    "        ],\n",
    "        job_arguments=[\"--project_name\", project_name,          # add more args as you want\n",
    "                       \"--user_name\",user_name,\n",
    "                       \"--BU_name\",BU_name,\n",
    "                      ]  \n",
    "\n",
    "\n",
    "    )\n",
    "    \n",
    "    #------------------------------------- TRAINING --------------------------------------------------------------------\n",
    "    \n",
    "    recommender_image_uri = config['DockerSpecific']['TrainingURI']\n",
    "    \n",
    "    estimator = Estimator(image_uri=recommender_image_uri,\n",
    "                      role=role,\n",
    "                      sagemaker_session=local_pipeline_session if mode=='local' else sagemaker_session,                                # Technical object\n",
    "                      #sagemaker_session = sagemaker_session,\n",
    "                      output_path=model_path,\n",
    "                      base_job_name=f'{project_name}-training-job',\n",
    "                      input_mode='File',\n",
    "                          entry_point = \"train.py\",\n",
    "                          source_dir = \"mlops_sampleusecase_training/model/\",# Copy the dataset and then train    \n",
    "                      train_instance_count=int(config['PipelineSpecific']['Training']['InstanceCount']),\n",
    "                      train_instance_type=config['PipelineSpecific']['Training']['InstanceType'],\n",
    "                      #train_instance_type = 'local' if mode=='local' else \"ml.m5.large\",\n",
    "                      debugger_hook_config=False,\n",
    "                      disable_profiler = True,\n",
    "                      metric_definitions=[\n",
    "                          # Only 40 Metrics can be accomodated\n",
    "                            {'Name': 'roc_auc_score' , 'Regex': 'roc_auc_score:([-+]?[0-9]*\\.?[0-9]+)'},\n",
    "                            {'Name': 'precision', 'Regex': 'precision:([-+]?[0-9]*\\.?[0-9]+)'},\n",
    "                            {'Name': 'recall_score', 'Regex': 'recall_score:([-+]?[0-9]*\\.?[0-9]+)'},\n",
    "                            {'Name': 'f1_score', 'Regex': 'f1_score:([-+]?[0-9]*\\.?[0-9]+)'},\n",
    "                            {'Name': 'accuracy_score', 'Regex': 'accuracy_score:([-+]?[0-9]*\\.?[0-9]+)'},\n",
    "                          \n",
    "                       ],\n",
    "                      tags = generic_tags + [{'Key': 'JobType', 'Value': 'Training'}],\n",
    "                      subnets = subnets.split(':'),\n",
    "                      security_group_ids = security_group_ids.split(':')\n",
    "                         )\n",
    "    print (project_name,user_name,BU_name)\n",
    "    \n",
    "    estimator.set_hyperparameters(\n",
    "    \n",
    "        project_name = project_name,\n",
    "        user_name=user_name,\n",
    "        BU_name = BU_name\n",
    "     )\n",
    "   \n",
    "    # start training\n",
    "    step_train = TrainingStep(\n",
    "        name= f\"{BUName}-{UsecaseName}-training\",\n",
    "        estimator= estimator,\n",
    "        inputs = {\n",
    "            \"input1\": TrainingInput(\n",
    "                #s3_data= \"s3://dlk-cloud-tier-10-preprocessed-ml-dev/awsworkshop/train/2022-08-31/output1/X.csv\",\n",
    "                s3_data = step_preprocess.properties.ProcessingOutputConfig.Outputs[\"output1\"].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "            \"input2\": TrainingInput(\n",
    "               # s3_data= \"s3://dlk-cloud-tier-10-preprocessed-ml-dev/awsworkshop/train/2022-08-31/output2/y.csv\",\n",
    "                s3_data = step_preprocess.properties.ProcessingOutputConfig.Outputs[\"output2\"].S3Output.S3Uri,\n",
    "               content_type=\"text/csv\",\n",
    "            ),\n",
    "\n",
    "        },\n",
    "       # depends_on = [step_preprocess]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    ###### --------------------- Model Registry ----------------------------------------------------------------\n",
    "    \n",
    "    #registering the model\n",
    "\n",
    "    step_register = RegisterModel(\n",
    "        name= f\"{BUName}-{UsecaseName}\",\n",
    "        estimator= estimator,\n",
    "        model_data= step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        content_types= [\"text/csv\"],\n",
    "        response_types= [\"text/csv\"],\n",
    "        inference_instances= [\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "        transform_instances= [\"ml.m5.xlarge\"],\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        approval_status=model_approval_status,\n",
    "        #model_metrics=model_metrics,\n",
    "    )\n",
    "\n",
    "    # ========================================= PIPELINE ORCHESTRATION ================================================\n",
    "    \n",
    "    # Pipeline instance\n",
    "    pipeline = Pipeline(\n",
    "        name=pipeline_name+env,\n",
    "        parameters=[\n",
    "            model_path,\n",
    "            model_approval_status\n",
    "        ],\n",
    "        steps=[\n",
    "            step_preprocess,\n",
    "            step_train,\n",
    "            step_register,\n",
    "              ],\n",
    "        #sagemaker_session=sagemaker_session,\n",
    "        sagemaker_session= local_pipeline_session if mode=='local' else sagemaker_session,\n",
    "    )\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1270aa1",
   "metadata": {},
   "source": [
    "![workflowimage](Images/pic8.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fbd1163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sampleproject-testing'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"UserDetails\"][\"ProjectName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b1fbf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_subnets = 'subnet-036d6b39301b4a41a'\n",
    "dev_sg = 'sg-0970930479bbef573'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a438aaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleproject-testing mlops-user1 mlops\n"
     ]
    }
   ],
   "source": [
    "region ='ap-southeast-1'\n",
    "role='arn:aws:iam::120582440665:role/Sagemaker'\n",
    "#role=None\n",
    "default_bucket='pipeline-sagemaker-test'\n",
    "pipeline_def = get_pipeline(region, \n",
    "                            dev_subnets, \n",
    "                            dev_sg, \n",
    "                            role,\n",
    "                            default_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ded16312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:ap-southeast-1:120582440665:pipeline/mlops-sample-usecase-pipeline-dev',\n",
       " 'ResponseMetadata': {'RequestId': '60fc0903-7ea8-4bcd-a8f7-59b11e36c287',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '60fc0903-7ea8-4bcd-a8f7-59b11e36c287',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '106',\n",
       "   'date': 'Mon, 24 Jul 2023 10:18:18 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_def.upsert(role_arn=role)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "416f1cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:ap-southeast-1:120582440665:pipeline/mlops-sample-usecase-pipeline-dev',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:ap-southeast-1:120582440665:pipeline/mlops-sample-usecase-pipeline-dev/execution/cpslerko4o3r',\n",
       " 'PipelineExecutionDisplayName': 'execution-1690193908825',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'CreationTime': datetime.datetime(2023, 7, 24, 10, 18, 28, 743000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2023, 7, 24, 10, 18, 28, 743000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {},\n",
       " 'LastModifiedBy': {},\n",
       " 'ResponseMetadata': {'RequestId': 'b6623de2-6e77-490e-8bd1-edef4751be11',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b6623de2-6e77-490e-8bd1-edef4751be11',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '441',\n",
       "   'date': 'Mon, 24 Jul 2023 10:18:28 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution = pipeline_def.start()\n",
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a39c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec3500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import boto3\n",
    "# s3 = boto3.client(\"s3\")\n",
    "# #s3://dlk-cloud-tier-9-training-ml-dev/experiment-report/mlops-experiment-trial-excel/\n",
    "# s3.download_file(\n",
    "#     Bucket=\"dlk-cloud-tier-9-training-ml-dev\", Key=\"experiment-report/mlops-experiment-trial-excel/mlops-model-performance-experiment.xlsx\", Filename=\"file5.xlsx\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4a7f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #------------------delete pipeline ------------------------\n",
    "# import boto3\n",
    "# sm_client = boto3.client(\"sagemaker\")\n",
    "# sm_client.delete_pipeline(PipelineName=\"mlops-sample-usecase-pipeline-dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1612cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
